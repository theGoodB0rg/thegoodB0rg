import base64
import json
import os
from collections import Counter
from datetime import datetime, timedelta, timezone

import requests

GITHUB_API = "https://api.github.com"
TOKEN = os.getenv("GITHUB_TOKEN", "")
USER = os.getenv("GH_PROFILE_USER", "").strip() or os.getenv("GITHUB_REPOSITORY_OWNER", "")
HEADERS = {"Authorization": f"Bearer {TOKEN}"} if TOKEN else {}
SESSION = requests.Session()
SESSION.headers.update({"Accept": "application/vnd.github+json", **HEADERS})

START_MARK = "<!--START_SECTION:autogenerated-->"
END_MARK = "<!--END_SECTION:autogenerated-->"
SELECTED_START = "<!--START_SECTION:selected_repos-->"
SELECTED_END = "<!--END_SECTION:selected_repos-->"

def gh_get(url, params=None):
    r = SESSION.get(url, params=params or {})
    r.raise_for_status()
    return r.json()

def gh_paged(url, params=None):
    params = params or {}
    params.setdefault("per_page", 100)
    page = 1
    while True:
        params["page"] = page
        r = SESSION.get(url, params=params)
        if r.status_code in (403, 429):
            print(f"Rate limit hit while fetching {url}; returning partial data.")
            break
        r.raise_for_status()
        data = r.json()
        if not data:
            break
        for item in data:
            yield item
        if len(data) < params["per_page"]:
            break
        page += 1

def list_public_repos(user):
    return list(gh_paged(f"{GITHUB_API}/users/{user}/repos", {"type": "owner", "sort": "updated", "direction": "desc"}))

def repo_languages(owner, repo):
    try:
        return gh_get(f"{GITHUB_API}/repos/{owner}/{repo}/languages")
    except requests.HTTPError:
        return {}

def get_file_json(owner, repo, path):
    try:
        data = gh_get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/{path}")
        if isinstance(data, dict) and "content" in data:
            content = base64.b64decode(data["content"]).decode("utf-8", errors="ignore")
            return json.loads(content)
    except Exception:
        pass
    return None

def file_exists(owner, repo, path):
    try:
        r = SESSION.get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/{path}")
        r.raise_for_status()
        return True
    except Exception:
        return False

def list_repo_paths(owner, repo, path=""):
    try:
        data = gh_get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/{path}")
        if isinstance(data, list):
            return [item.get("path", "") for item in data]
        return []
    except Exception:
        return []

def detect_stack(owner, repo):
    stacks = set()
    if file_exists(owner, repo, "Dockerfile") or file_exists(owner, repo, "docker-compose.yml"):
        stacks.add("Docker")
    if any(p.startswith(".github/workflows/") for p in list_repo_paths(owner, repo, ".github/workflows")):
        stacks.add("GitHub Actions (CI/CD)")
    tf_present = any(p.endswith(".tf") for p in list_repo_paths(owner, repo))
    if tf_present:
        stacks.add("Terraform")
    for candidate in ["k8s", "deploy", "deployments", "manifests"]:
        if file_exists(owner, repo, candidate):
            stacks.add("Kubernetes")
            break

    pkg = get_file_json(owner, repo, "package.json")
    if pkg:
        deps = {**pkg.get("dependencies", {}), **pkg.get("devDependencies", {})}
        keys = {k.lower() for k in deps.keys()}
        if "react" in keys:
            stacks.add("React")
        if "next" in keys or "nextjs" in keys or "next.js" in keys:
            stacks.add("Next.js")
        if "vue" in keys or "nuxt" in keys:
            stacks.add("Vue")
        if any(k in keys for k in ["angular", "@angular/core"]):
            stacks.add("Angular")
        if any(k in keys for k in ["svelte", "@sveltejs/kit"]):
            stacks.add("Svelte")
        if any(k in keys for k in ["express", "fastify", "koa", "nestjs", "@nestjs/core"]):
            stacks.add("Node.js API")
        if any(k in keys for k in ["typeorm", "prisma", "mongoose", "pg", "mysql", "sqlite3", "redis"]):
            stacks.add("Databases")
        if any(k in keys for k in ["tailwindcss", "vite", "webpack", "rollup"]):
            stacks.add("Frontend Tooling")

    for f in ["requirements.txt", "pyproject.toml", "Pipfile"]:
        if file_exists(owner, repo, f):
            stacks.add("Python")
            try:
                data = SESSION.get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/requirements.txt").json()
                if isinstance(data, dict) and "content" in data:
                    content = base64.b64decode(data["content"]).decode("utf-8", errors="ignore").lower()
                    if "django" in content:
                        stacks.add("Django")
                    if "flask" in content:
                        stacks.add("Flask")
                    if "fastapi" in content:
                        stacks.add("FastAPI")
                    if any(db in content for db in ["psycopg2", "sqlalchemy", "pymongo", "redis", "mysqlclient"]):
                        stacks.add("Databases")
            except Exception:
                pass

    if file_exists(owner, repo, "go.mod"):
        stacks.add("Go")
        try:
            data = SESSION.get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/go.mod").json()
            if isinstance(data, dict) and "content" in data:
                content = base64.b64decode(data["content"]).decode("utf-8", errors="ignore").lower()
                if "github.com/gin-gonic/gin" in content:
                    stacks.add("Gin")
                if "github.com/gofiber/fiber" in content:
                    stacks.add("Fiber")
                if "github.com/labstack/echo" in content:
                    stacks.add("Echo")
                if "github.com/gorilla/mux" in content:
                    stacks.add("Gorilla Mux")
        except Exception:
            pass

    if file_exists(owner, repo, "Cargo.toml"):
        stacks.add("Rust")
    if file_exists(owner, repo, "pom.xml") or file_exists(owner, repo, "build.gradle") or file_exists(owner, repo, "build.gradle.kts"):
        stacks.add("JVM")
    if file_exists(owner, repo, "composer.json"):
        stacks.add("PHP")
    if file_exists(owner, repo, "Gemfile"):
        stacks.add("Ruby")
    if any(p.endswith(".csproj") for p in list_repo_paths(owner, repo)):
        stacks.add(".NET")
    if file_exists(owner, repo, "pubspec.yaml"):
        stacks.add("Flutter")
    return stacks

def aggregate_languages(repos):
    lang_bytes = Counter()
    for r in repos:
        langs = repo_languages(r["owner"]["login"], r["name"])
        for k, v in langs.items():
            lang_bytes[k] += v
    total = sum(lang_bytes.values()) or 1
    top = lang_bytes.most_common(8)
    top_pct = [(k, round(v * 100.0 / total, 1)) for k, v in top]
    return top_pct

def aggregate_stacks(repos):
    counts = Counter()
    for r in repos:
        for s in detect_stack(r["owner"]["login"], r["name"]):
            counts[s] += 1
    return counts.most_common()

def user_achievements(user, repos):
    stars = sum(r.get("stargazers_count", 0) for r in repos)
    forks = sum(r.get("forks_count", 0) for r in repos)
    releases = 0
    for r in repos:
        try:
            rel = gh_get(f"{GITHUB_API}/repos/{r['owner']['login']}/{r['name']}/releases/latest")
            if isinstance(rel, dict) and rel.get("tag_name"):
                releases += 1
        except requests.HTTPError:
            pass
    return {"stars": stars, "forks": forks, "repos_with_releases": releases}

def recent_activity(user, days=30, limit=10):
    cutoff = datetime.now(timezone.utc) - timedelta(days=days)
    try:
        events = list(gh_paged(f"{GITHUB_API}/users/{user}/events/public"))
    except requests.HTTPError as exc:
        status = getattr(exc.response, "status_code", None)
        if status == 429:
            print("Rate limit hit while fetching recent activity; skipping this section.")
            return []
        raise
    items = []
    for e in events:
        created = datetime.fromisoformat(e["created_at"].replace("Z", "+00:00"))
        if created < cutoff:
            continue
        et = e.get("type")
        repo = e.get("repo", {}).get("name", "")
        if et in ("PushEvent", "PullRequestEvent", "IssuesEvent", "ReleaseEvent"):
            items.append(f"{created.date()} - {et.replace('Event','')} - {repo}")
        if len(items) >= limit:
            break
    return items

def build_auto_section(data):
    lines = []
    lines.append("## Auto-generated snapshot")
    lines.append("")
    lines.append(f"- Total Stars: {data['achievements']['stars']}")
    lines.append(f"- Total Forks: {data['achievements']['forks']}")
    lines.append(f"- Repos with Releases: {data['achievements']['repos_with_releases']}")
    lines.append("")
    lines.append("### Top Languages")
    lines.append(", ".join([f"{k} ({v}%)" for k, v in data["top_languages"]]) or "N/A")
    lines.append("")
    if data["stacks"]:
        lines.append("### Detected Stacks")
        lines.append(", ".join([f"{k} Ã—{v}" for k, v in data["stacks"]]))
        lines.append("")
    if data["recent_activity"]:
        lines.append("### Recent Activity")
        for a in data["recent_activity"]:
            lines.append(f"- {a}")
        lines.append("")
    lines.append(f"_Last updated: {data['last_updated']}_")
    return "\n".join(lines)

def replace_between_markers(src, new_block, start_marker, end_marker):
    if start_marker not in src or end_marker not in src:
        return None  # markers missing
    pre, rest = src.split(start_marker, 1)
    if end_marker not in rest:
        return None
    _, post = rest.split(end_marker, 1)
    replacement = f"{start_marker}\n{new_block}\n{end_marker}"
    return pre + replacement + post


def load_selected_repos(path="selected_repos.json"):
    if not os.path.exists(path):
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except json.JSONDecodeError:
        print(f"Failed to parse {path}; ensure it contains valid JSON.")
        return []
    except OSError as exc:
        print(f"Could not read {path}: {exc}")
        return []

    sanitized = []
    for item in data:
        title = (item.get("title") or "").strip()
        summary = (item.get("summary") or item.get("description") or "").strip()
        links = item.get("links") or []
        if not title or not summary:
            continue
        cleaned_links = []
        for link in links:
            label = (link.get("label") or "").strip()
            url = (link.get("url") or "").strip()
            if label and url:
                cleaned_links.append({"label": label, "url": url})
        sanitized.append({"title": title, "summary": summary, "links": cleaned_links})
    return sanitized


def build_selected_section(items):
    if not items:
        return ""
    lines = []
    for item in items:
        lines.append(f"- {item['title']} - {item['summary']}  ")
        for link in item.get("links", []):
            lines.append(f"  - {link['label']}: {link['url']}")
    return "\n".join(lines)

def main():
    if not USER:
        raise SystemExit("GH_PROFILE_USER or GITHUB_REPOSITORY_OWNER not set")

    repos = list_public_repos(USER)

    auto_block = None
    if repos:
        top_languages = aggregate_languages(repos)
        stacks = aggregate_stacks(repos)
        achievements = user_achievements(USER, repos)
        activity = recent_activity(USER, days=30, limit=10)
        now_str = datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")

        data = {
            "top_languages": top_languages,
            "stacks": stacks,
            "achievements": achievements,
            "recent_activity": activity,
            "last_updated": now_str,
        }

        auto_block = build_auto_section(data)
    else:
        print('No repository data fetched; metrics section will not be updated this run.')

    # Only update between markers; never overwrite the whole file
    if not os.path.exists("README.md"):
        print("README.md not found; aborting to avoid creating a generic file.")
        return

    with open("README.md", "r", encoding="utf-8") as f:
        original = f.read()

    updated = original
    changed = False

    if auto_block is not None:
        auto_updated = replace_between_markers(updated, auto_block, START_MARK, END_MARK)
        if auto_updated is None:
            print("Auto-update markers not found in README.md; no changes made to stats section.")
        else:
            if auto_updated != updated:
                changed = True
            updated = auto_updated
    else:
        print('Stats section skipped because no repository data was retrieved.')

    selected_items = load_selected_repos()
    if selected_items:
        selected_block = build_selected_section(selected_items)
        selected_updated = replace_between_markers(updated, selected_block, SELECTED_START, SELECTED_END)
        if selected_updated is None:
            print("Selected repos markers not found in README.md; skipped updating project highlights.")
        else:
            if selected_updated != updated:
                changed = True
            updated = selected_updated
    else:
        print("No selected repos data found; skipped updating project highlights.")

    if changed and original.strip() != updated.strip():
        with open("README.md", "w", encoding="utf-8") as f:
            f.write(updated)
        print("README.md updated within designated sections.")
    else:
        print("README.md unchanged (no diff within designated sections).")

if __name__ == "__main__":
    main()
