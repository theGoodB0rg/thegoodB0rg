import base64
import json
import os
from collections import Counter
from datetime import datetime, timedelta, timezone

import requests

GITHUB_API = "https://api.github.com"
TOKEN = os.getenv("GITHUB_TOKEN", "")
USER = os.getenv("GH_PROFILE_USER", "").strip() or os.getenv("GITHUB_REPOSITORY_OWNER", "")
HEADERS = {"Authorization": f"Bearer {TOKEN}"} if TOKEN else {}
SESSION = requests.Session()
SESSION.headers.update({"Accept": "application/vnd.github+json", **HEADERS})

START_MARK = "<!--START_SECTION:autogenerated-->"
END_MARK = "<!--END_SECTION:autogenerated-->"

def gh_get(url, params=None):
    r = SESSION.get(url, params=params or {})
    r.raise_for_status()
    return r.json()

def gh_paged(url, params=None):
    params = params or {}
    params.setdefault("per_page", 100)
    page = 1
    while True:
        params["page"] = page
        r = SESSION.get(url, params=params)
        r.raise_for_status()
        data = r.json()
        if not data:
            break
        for item in data:
            yield item
        if len(data) < params["per_page"]:
            break
        page += 1

def list_public_repos(user):
    return list(gh_paged(f"{GITHUB_API}/users/{user}/repos", {"type": "owner", "sort": "updated", "direction": "desc"}))

def repo_languages(owner, repo):
    try:
        return gh_get(f"{GITHUB_API}/repos/{owner}/{repo}/languages")
    except requests.HTTPError:
        return {}

def get_file_json(owner, repo, path):
    try:
        data = gh_get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/{path}")
        if isinstance(data, dict) and "content" in data:
            content = base64.b64decode(data["content"]).decode("utf-8", errors="ignore")
            return json.loads(content)
    except Exception:
        pass
    return None

def file_exists(owner, repo, path):
    try:
        r = SESSION.get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/{path}")
        r.raise_for_status()
        return True
    except Exception:
        return False

def list_repo_paths(owner, repo, path=""):
    try:
        data = gh_get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/{path}")
        if isinstance(data, list):
            return [item.get("path", "") for item in data]
        return []
    except Exception:
        return []

def detect_stack(owner, repo):
    stacks = set()
    if file_exists(owner, repo, "Dockerfile") or file_exists(owner, repo, "docker-compose.yml"):
        stacks.add("Docker")
    if any(p.startswith(".github/workflows/") for p in list_repo_paths(owner, repo, ".github/workflows")):
        stacks.add("GitHub Actions (CI/CD)")
    tf_present = any(p.endswith(".tf") for p in list_repo_paths(owner, repo))
    if tf_present:
        stacks.add("Terraform")
    for candidate in ["k8s", "deploy", "deployments", "manifests"]:
        if file_exists(owner, repo, candidate):
            stacks.add("Kubernetes")
            break

    pkg = get_file_json(owner, repo, "package.json")
    if pkg:
        deps = {**pkg.get("dependencies", {}), **pkg.get("devDependencies", {})}
        keys = {k.lower() for k in deps.keys()}
        if "react" in keys:
            stacks.add("React")
        if "next" in keys or "nextjs" in keys or "next.js" in keys:
            stacks.add("Next.js")
        if "vue" in keys or "nuxt" in keys:
            stacks.add("Vue")
        if any(k in keys for k in ["angular", "@angular/core"]):
            stacks.add("Angular")
        if any(k in keys for k in ["svelte", "@sveltejs/kit"]):
            stacks.add("Svelte")
        if any(k in keys for k in ["express", "fastify", "koa", "nestjs", "@nestjs/core"]):
            stacks.add("Node.js API")
        if any(k in keys for k in ["typeorm", "prisma", "mongoose", "pg", "mysql", "sqlite3", "redis"]):
            stacks.add("Databases")
        if any(k in keys for k in ["tailwindcss", "vite", "webpack", "rollup"]):
            stacks.add("Frontend Tooling")

    for f in ["requirements.txt", "pyproject.toml", "Pipfile"]:
        if file_exists(owner, repo, f):
            stacks.add("Python")
            try:
                data = SESSION.get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/requirements.txt").json()
                if isinstance(data, dict) and "content" in data:
                    content = base64.b64decode(data["content"]).decode("utf-8", errors="ignore").lower()
                    if "django" in content:
                        stacks.add("Django")
                    if "flask" in content:
                        stacks.add("Flask")
                    if "fastapi" in content:
                        stacks.add("FastAPI")
                    if any(db in content for db in ["psycopg2", "sqlalchemy", "pymongo", "redis", "mysqlclient"]):
                        stacks.add("Databases")
            except Exception:
                pass

    if file_exists(owner, repo, "go.mod"):
        stacks.add("Go")
        try:
            data = SESSION.get(f"{GITHUB_API}/repos/{owner}/{repo}/contents/go.mod").json()
            if isinstance(data, dict) and "content" in data:
                content = base64.b64decode(data["content"]).decode("utf-8", errors="ignore").lower()
                if "github.com/gin-gonic/gin" in content:
                    stacks.add("Gin")
                if "github.com/gofiber/fiber" in content:
                    stacks.add("Fiber")
                if "github.com/labstack/echo" in content:
                    stacks.add("Echo")
                if "github.com/gorilla/mux" in content:
                    stacks.add("Gorilla Mux")
        except Exception:
            pass

    if file_exists(owner, repo, "Cargo.toml"):
        stacks.add("Rust")
    if file_exists(owner, repo, "pom.xml") or file_exists(owner, repo, "build.gradle") or file_exists(owner, repo, "build.gradle.kts"):
        stacks.add("JVM")
    if file_exists(owner, repo, "composer.json"):
        stacks.add("PHP")
    if file_exists(owner, repo, "Gemfile"):
        stacks.add("Ruby")
    if any(p.endswith(".csproj") for p in list_repo_paths(owner, repo)):
        stacks.add(".NET")
    if file_exists(owner, repo, "pubspec.yaml"):
        stacks.add("Flutter")
    return stacks

def aggregate_languages(repos):
    lang_bytes = Counter()
    for r in repos:
        langs = repo_languages(r["owner"]["login"], r["name"])
        for k, v in langs.items():
            lang_bytes[k] += v
    total = sum(lang_bytes.values()) or 1
    top = lang_bytes.most_common(8)
    top_pct = [(k, round(v * 100.0 / total, 1)) for k, v in top]
    return top_pct

def aggregate_stacks(repos):
    counts = Counter()
    for r in repos:
        for s in detect_stack(r["owner"]["login"], r["name"]):
            counts[s] += 1
    return counts.most_common()

def user_achievements(user, repos):
    stars = sum(r.get("stargazers_count", 0) for r in repos)
    forks = sum(r.get("forks_count", 0) for r in repos)
    releases = 0
    for r in repos:
        try:
            rel = gh_get(f"{GITHUB_API}/repos/{r['owner']['login']}/{r['name']}/releases/latest")
            if isinstance(rel, dict) and rel.get("tag_name"):
                releases += 1
        except requests.HTTPError:
            pass
    return {"stars": stars, "forks": forks, "repos_with_releases": releases}

def recent_activity(user, days=30, limit=10):
    cutoff = datetime.now(timezone.utc) - timedelta(days=days)
    events = list(gh_paged(f"{GITHUB_API}/users/{user}/events/public"))
    items = []
    for e in events:
        created = datetime.fromisoformat(e["created_at"].replace("Z", "+00:00"))
        if created < cutoff:
            continue
        et = e.get("type")
        repo = e.get("repo", {}).get("name", "")
        if et in ("PushEvent", "PullRequestEvent", "IssuesEvent", "ReleaseEvent"):
            items.append(f"{created.date()} - {et.replace('Event','')} - {repo}")
        if len(items) >= limit:
            break
    return items

def build_auto_section(data):
    lines = []
    lines.append("## Auto-generated snapshot")
    lines.append("")
    lines.append(f"- Total Stars: {data['achievements']['stars']}")
    lines.append(f"- Total Forks: {data['achievements']['forks']}")
    lines.append(f"- Repos with Releases: {data['achievements']['repos_with_releases']}")
    lines.append("")
    lines.append("### Top Languages")
    lines.append(", ".join([f"{k} ({v}%)" for k, v in data["top_languages"]]) or "N/A")
    lines.append("")
    if data["stacks"]:
        lines.append("### Detected Stacks")
        lines.append(", ".join([f"{k} Ã—{v}" for k, v in data["stacks"]]))
        lines.append("")
    if data["recent_activity"]:
        lines.append("### Recent Activity")
        for a in data["recent_activity"]:
            lines.append(f"- {a}")
        lines.append("")
    lines.append(f"_Last updated: {data['last_updated']}_")
    return "\n".join(lines)

def replace_between_markers(src, new_block):
    if START_MARK not in src or END_MARK not in src:
        return None  # markers missing
    pre, rest = src.split(START_MARK, 1)
    if END_MARK not in rest:
        return None
    mid, post = rest.split(END_MARK, 1)
    replacement = f"{START_MARK}\n{new_block}\n{END_MARK}"
    return pre + replacement + post

def main():
    if not USER:
        raise SystemExit("GH_PROFILE_USER or GITHUB_REPOSITORY_OWNER not set")

    repos = list_public_repos(USER)
    top_languages = aggregate_languages(repos)
    stacks = aggregate_stacks(repos)
    achievements = user_achievements(USER, repos)
    activity = recent_activity(USER, days=30, limit=10)
    now_str = datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")

    data = {
        "top_languages": top_languages,
        "stacks": stacks,
        "achievements": achievements,
        "recent_activity": activity,
        "last_updated": now_str,
    }

    auto_block = build_auto_section(data)

    # Only update between markers; never overwrite the whole file
    if not os.path.exists("README.md"):
        print("README.md not found; aborting to avoid creating a generic file.")
        return

    with open("README.md", "r", encoding="utf-8") as f:
        original = f.read()

    updated = replace_between_markers(original, auto_block)
    if updated is None:
        print("Auto-update markers not found in README.md; no changes made.")
        return

    if original.strip() != updated.strip():
        with open("README.md", "w", encoding="utf-8") as f:
            f.write(updated)
        print("README.md updated within markers.")
    else:
        print("README.md unchanged (no diff within markers).")

if __name__ == "__main__":
    main()
